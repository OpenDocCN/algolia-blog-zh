<html>
<head>
<title>The convolutional neural network explained | Algolia Blog</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络解释</h1>
<blockquote>原文：<a href="https://www.algolia.com/blog/ai/whats-a-convolutional-neural-network-and-how-is-it-used-for-image-recognition-in-search/#0001-01-01">https://www.algolia.com/blog/ai/whats-a-convolutional-neural-network-and-how-is-it-used-for-image-recognition-in-search/#0001-01-01</a></blockquote><div><div class="css-t54cg4"><p class="translated"><b>社交媒体用户</b> <span>被展示了基于人脸识别技术他可能认识的人的快照，并被询问是否想在应用程序中将他们添加为好友。</span></p>
<p class="translated"><b>一辆行驶在城市街道上的自动驾驶汽车</b> <span>使用视觉识别技术进行物体检测，“看到”一名行人即将走下路边并在它面前乱穿马路，并决定通过减速做出反应。</span></p>
<p class="translated"><b>一名医生</b> <span>能够使用技术比较数千张x光韧带的可比医疗图像，从而自信地诊断她的病人的状况，并排除恶性癌细胞的存在。</span></p>
<p class="translated"><b>一个警察部门</b> <span>生成一张嫌疑犯的清晰照片，警察可以把它放在手边。但这还不是全部:通过生成对抗网络(GANs)，图像可以用来训练面部识别的深度学习模型。</span></p>
<p class="translated"><b>一家在线零售商</b> <span>建议人们用其他人选择搭配的上衣、夹克和配饰来“完善”他们正在考虑的牛仔裤，社交媒体图像数据证明了这一点。</span></p>
<h2 class="translated"><a id="versatile-visual-image-recognition" class="anchor" href="#versatile-visual-image-recognition" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a> <span>多功能视觉图像识别</span></h2>
<p class="translated">这些是图像识别系统的一些最新应用，更广泛地称为计算机视觉:机器表面上像人一样“看”，以同样的视觉方式感知人类环境。</p>
<p class="translated">所有这些图像识别和分类应用程序有什么共同点？它们由称为卷积神经网络(CNN，简称ConvNet)的机器学习子集专业处理。</p>
<h2 class="translated"><a id="definition-of-a-convolutional-neural-network" class="anchor" href="#definition-of-a-convolutional-neural-network" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a> <span>卷积神经网络的定义</span></h2>
<p class="translated"><span>在</span> <a href="https://www.algolia.com/blog/preview/?id=17882"> <span>类神经网络</span> </a> <span>中脱颖而出，卷积神经网络是一种深度学习的网络架构，它从接收到的数据中进行学习。在各种类型的神经网络中，CNN最擅长识别图像(和视频；另外，它们擅长语音和音频信号)。事实上，对于CNN，数据输入被认为是与图像相关的。</span></p>
<p class="translated"><span>在其图像处理周期中，卷积网络可以评估图像，为图像的各个方面分配重要性级别，并区分其视觉元素。</span></p>
<p class="translated"><span>CNN操作结构的创建受到了大脑中神经元连接方式的启发，特别是动物视觉皮层的组织方式。神经元只在特定的区域——感受野——对刺激做出反应。各种感受野重叠覆盖视觉区。</span></p>
<h2 class="translated"><a id="seeing-eye-pcs" class="anchor" href="#seeing-eye-pcs" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a> <span>导盲犬？</span></h2>
<p class="translated"><span>一个没有眼睛的机器是如何熟练掌握模式识别，在卷积运算中解释图像的？你猜对了:借助人工智能。</span></p>
<p class="translated"><span>卷积神经网络架构包括一个模型，一系列统计函数，计算和重新计算数字的像素化向量，直到图像被识别和分类。由于利用了数字(权重)、统计和通过节点(神经元或输入)对数据的处理，它可以“看见”，这些节点具有与之相关联的权重和阈值。</span></p>
<p class="translated"><span>这种图像识别技术的第一步:将图像的像素值转换成称为矢量的数值，从而可以解释图像和提取图案。完成后，就可以输入数据了。</span></p>
<p class="translated"><span>深度学习的CNN有几种类型的节点层，每一层都学习检测图像的不同特征。在每一层中，应用过滤器(一个</span> <a href="https://www.techtarget.com/searchdatacenter/definition/kernel"> <span>内核</span> </a> <span>或特征检测器)，移动穿过图像的感受野，检查某些特征是否存在并激活某些特征。</span></p>
<p class="translated">一层中的所有节点连接到下一层中的每个激活单元或节点。如果一个节点的输出高于指定的阈值，则该节点被激活，其数据被传递到连接节点。</p>
<h2 class="translated"><a id="the-nodes-know" class="anchor" href="#the-nodes-know" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a> <span>节点知道</span></h2>
<p class="translated"><span>在初始处理层中，重点是解读图像中的直观特征，如颜色和元素边缘。随着每一次连续的层迭代，过滤器活动深入到更复杂的地方，识别代表输入的元素。</span></p>
<p class="translated"><span>在每一层中创建的部分识别的图像作为下一层的输入被推进。对于每一层，CNN识别出图像的更大部分。</span></p>
<p class="translated"><span>每次扫描后，计算一个</span> <a href="https://www.techtarget.com/whatis/definition/dot-product-scalar-product"> <span>点积</span> </a> <span>。这一系列点的输出被称为特征图。</span></p>
<p class="translated"><span>通过多次扫描，整个图像被处理，算法识别图像中的内容。</span></p>
<p class="translated">这种细化过程可以重复几十层、几百层甚至几千层，使图像逐渐变得更好、更详细。</p>
<p class="translated">这一壮举本身就令人印象深刻。但是还有更多。</p>
<p class="translated">由于CNN可能会处理数百万张图像，该模型会记录、校准并重新调整其权重。最终，它对自己看到的东西变得非常自信，几乎可以识别任何图像。在整个CNN世界，深度学习处理技能的完善意味着 <span>计算机视觉领域一直在突飞猛进。</span></p>
<h2 class="translated"><a id="multiple-layers" class="anchor" href="#multiple-layers" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a> <span>多层</span></h2>
<p class="translated">CNN识别图像的关键是从一层到下一层增加复杂程度。不同的CNN专家引用了不同数量的CNN层(其中一些是隐藏层)。不管这些不一致，结果是一样的:图像的准确解释。</p>
<p class="translated"><span>除了基线输入层和输出层，构造块层还包括:</span></p>
<h3 class="translated"><a id="the-convolutional-layer" class="anchor" href="#the-convolutional-layer" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a> <span>卷积层</span></h3>
<p class="translated"><span>这第一层是进行大部分计算的地方。可以包括在初始层之后用于附加分类的第二卷积层，以便于从图像中提取高级特征。</span></p>
<h3 class="translated"><a id="the-pooling-layer" class="anchor" href="#the-pooling-layer" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a> <span>共用层</span></h3>
<p class="translated"><span>这一层降低了视觉表示的复杂性/维度——输入中的参数数量——因此丢失了一些信息。这个</span> <a href="https://deeplearning.cs.cmu.edu/F20/document/slides/lec10.CNN.pdf"> <span>下采样</span> </a> <span>层提高了效率，限制了</span> <a href="https://medium.com/mlearning-ai/underfitting-and-overfitting-in-deep-learning-687b1b7eb738#:~:text=In%20Short%3A%20Overfitting%20means%20that,performs%20poorly%20on%20both%20datasets."> <span>过拟合</span> </a> <span>的风险。</span></p>
<p class="translated"><span>有两种类型的池操作:</span></p>
<ul>
<li aria-level="1" class="translated"><b> Max pooling: </b> <span>当过滤器扫描输入图像时，它选择具有最大值的像素传递给输出数组。</span></li>
</ul>
<ul>
<li aria-level="1" class="translated"><b>平均池:</b> <span>当过滤器扫描时，它计算接收域内的平均值，并传递给输出数组。此方法的使用频率低于最大池。</span></li>
</ul>
<h3 class="translated"><a id="the-fully-connected-layer" class="anchor" href="#the-fully-connected-layer" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a> <span>【全连通层】</span></h3>
<p class="translated"><span>这是根据提取的特征对图像进行分类的层。这最后一层是“完全连接的”(FC)，因为它的节点与另一层中的节点或激活单元连接。</span></p>
<h2 class="translated"><a id="cnns-are-superior" class="anchor" href="#cnns-are-superior" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a><span>CNN是上级</span></h2>
<p class="translated"><span>谈到视觉感知，为什么CNN比常规神经网络(NNs)更好？</span></p>
<p class="translated"><span>常规神经网络(NNs)无法伸缩。它们没有CNN那样的计算能力和资源。神经网络可能试图学习训练数据中过多的细节(称为过度拟合)。如果你将数百万张照片输入计算机，并要求它考虑图像识别工作中的每一个重要细节，包括视觉“噪音”，这可能会扭曲图像分类。</span></p>
<p class="translated">CNN架构对图像更好，因为它利用了一种称为参数共享的方法，与NN相比，这降低了计算强度。在它的每一层中，每个节点都连接到另一个节点。随着过滤器在给定层中穿过图像，相关联的权重保持固定。</p>
<h2 class="translated"><a id="how-cnns-have-improved-image-recognition-in-search" class="anchor" href="#how-cnns-have-improved-image-recognition-in-search" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a><span>CNN如何在搜索中提高图像识别能力</span></h2>
<p class="translated"><span>得益于CNN对视觉信息的精准处理，对图像的分类，以及计算机视觉的提升，</span> <a href="https://www.algolia.com/blog/product/picture-search-how-does-an-image-finder-search-engine-work/"> <span>视觉搜索</span> </a> <span>的领域得到了爆发。这种视觉处理现象在电子商务中尤为明显，网站现在可以为用户提供</span> <a href="https://www.algolia.com/blog/ai/visual-shopping-visual-discovery-how-image-search-is-changing-online-shopping/"> <span>视觉购物</span> </a> <span>的优势和乐趣。</span></p>
<p class="translated"><span>在Algolia，我们帮助公司让现实生活中的人们更容易使用图片搜索来准确找到他们想要的商品，并通过“完成外观”等功能鼓励追加销售。</span></p>
<p class="translated"><span>想用我们CNN辅助的</span> <a href="https://www.algolia.com/products/search-and-discovery/image-search/"> <span>图片搜索</span> </a> <span>技术提升你的网站搜索结果？</span> <a href="https://www.algolia.com/contactus/"> <span>联系我们</span> </a> <span>我们会帮你发现并追求所有的可能性。</span></p>
</div></div>    
</body>
</html>