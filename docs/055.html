<html>
<head>
<title>Generate a transcription index for your YouTube content using Whisper - Algolia Blog | Algolia Blog</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Whisper-Algolia Blog | Algolia Blog为您的YouTube内容生成转录索引</h1>
<blockquote>原文：<a href="https://www.algolia.com/blog/engineering/generate-a-transcription-index-for-youtube-using-whisper/#0001-01-01">https://www.algolia.com/blog/engineering/generate-a-transcription-index-for-youtube-using-whisper/#0001-01-01</a></blockquote><div><div class="css-t54cg4"><p class="translated">我们2022年Algolia开发者大会的主题是“索引世界，让您的数据动起来”，所以很自然地，当最后一个视频上传到YouTube时，话题就转向了我们如何为我们的客户让所有这些伟大的新内容动起来。</p>
<p class="translated">我知道我希望这些视频可以通过标题和描述进行搜索，并且可以通过类别进行搜索，但是我还想做得更多。我希望能够帮助开发者在视频中找到与他们的搜索相匹配的确切位置。这意味着将视频的抄本编入索引。我们过去曾尝试过使用YouTube的字幕功能来实现这一点，结果是混合的<a href="https://github.com/algolia/youtube-captions-scraper"/>。对我们来说幸运的是，几乎在同一时间，OpenAI的团队发布了一种新的神经网络，称为<a href="https://openai.com/blog/whisper/">耳语</a>，用于自动语音识别。</p>
<p class="translated">在这篇文章的其余部分，我将描述我用来构建A/VSearch CLI的工具链，这是一个集成的命令行，用于从YouTube频道或播放列表生成和索引脚本。</p>
<p class="translated">您可以在我们的演示网站<a href="https://avsearch.vercel.app/">查看结果，点击这里</a>！</p>
<h2 class="translated"><a id="machine-learning-whisper" class="anchor" href="#machine-learning-whisper" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a>机器学习——耳语</h2>
<p class="translated">如上所述，<a href="https://openai.com"> OpenAI </a>最近发布了<a href="https://github.com/openai/whisper"> Whisper </a>这是一款通用的语音识别模型。它可以识别许多不同的语言，甚至有能力在它们之间进行翻译。由于它是在Python中自然公开的，所以它是与Algolia的Python API客户端合作的最佳人选。总的来说，我对转录质量印象深刻。即使使用<code>medium</code>模型，减去一些具体的技术名称，它转录视频没有一个错误。</p>
<p class="translated">我个人希望Whisper拥有的一个大功能是<a href="https://en.wikipedia.org/wiki/Speaker_diarisation">扬声器二进制化</a>，该模型在整个录音中识别不同的扬声器，并确定那个人何时说话。现在，您必须手动清理并分配段给一个扬声器。可以将Whisper与另一个工具结合使用，比如<a href="https://github.com/pyannote/pyannote-audio"> PyAnnote </a>来实现这一点，我希望在未来将它作为一个特性添加进来。我还认为，在同一音频文件中使用多种语言时，Whisper有一定的局限性，但随着时间的推移，这种局限性会得到改善。</p>
<p class="translated">由于Whisper提供的片段有时非常短，因此很难确定片段的真实上下文。因此，我们添加了一个包含前一段和后一段的<code>context</code>字段。通过这种方式，可以清楚地了解特定片段中正在讨论的内容，从而提高找到特定剪辑的成功率。</p>
<h2 class="translated"><a id="how-i-built-it" class="anchor" href="#how-i-built-it" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a>我是怎么造出来的</h2>
<p class="translated">因为Whisper需要一个音频文件来运行转录，所以我需要一个方法来获取YouTube视频并将其转换为音频文件。<a href="https://github.com/ytdl-org/youtube-dl"> YouTube-DL </a>是我的选择，因为它在Python中得到很好的支持，我可以让它只下载视频的音频，这样我就不必在转录之前转换任何下载。由于一些用户想从命令行使用该程序，我添加了<a href="https://click.palletsprojects.com/en/8.1.x"> Click </a>库来支持CLI界面。</p>
<p class="translated">有时有些单词(或公司名称)是Whisper无法检测到的，所以我创建了它，以便您可以提供模式来执行搜索/替换逻辑。我的同事Chuck想出了一个好主意，也添加了一个分类功能，您可以在转录过程中为A/VSearch提供关键字，并自动应用预定义的类别。要使用这些特性，您只需传递一个JSON文件，其中包含定义的模式，A/VSearch将在这个过程中解析并使用它们。</p>
<h2 class="translated"><a id="how-to-use-it" class="anchor" href="#how-to-use-it" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a>怎么用</h2>
<p class="translated">使用A/VSearch非常简单，你可以从GitHub下载一个版本并安装，或者只需使用<code>pip</code>通过GitHub URL安装，它将加载最新版本。由于它有一个功能齐全的CLI，您可以只导出您的Algolia凭据作为环境变量，并开始行动！CLI接受播放列表、频道和单个视频的URL，并将文字记录写入您提供的Algolia索引名称。</p>
<p class="translated">Whisper的转录速度可以通过访问GPU来加快。使用NVIDIA Tesla T4 GPU转录一个三分钟的视频需要25秒，而在32-vCPU虚拟机上相同的视频需要45秒。这种增加对于较长的视频特别有帮助，因为它可能需要一小部分时间来处理。</p>
<pre><code class="lang:sh decode:true"># Create and activate a virtualenv&#13;
python3 -m venv av-search-test &amp;&amp; cd av-search-test&#13;
source bin/activate&#13;
&#13;
# Install via Pip or grab a release from GitHub&#13;
python3 -m pip install git+https://github.com/algolia-samples/avsearch&#13;
&#13;
export ALGOLIA_APP_ID=AAAAA12345&#13;
export ALGOLIA_INDEX_NAME=transcriptions&#13;
export ALGOLIA_API_KEY=6c4dba625a960b4cc54b7b5312f9117d&#13;
&#13;
# Transcribe a video, playlist, channel, etc.&#13;
av-search --targets "https://www.youtube.com/watch?v=epSVL87_sqA"&#13;
</code></pre>
<p class="translated">关于高级用法的更多信息可以在GitHub <a href="https://github.com/algolia-samples/avsearch">资源库</a>中找到。</p>
<h2 class="translated"><a id="how-to-automate-it" class="anchor" href="#how-to-automate-it" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a>如何实现自动化</h2>
<p class="translated">自动化A/VSearch的最佳方式是将其集成到Python应用程序中。这样，您可以优雅地处理任何错误，并轻松地集成任何其他可能需要的解决方案(例如事件通知)。)</p>
<pre><code class="lang:python decode:true">from avsearch import AVSearch&#13;
import os&#13;
&#13;
avs = AVSearch(app_id='AAAAA12345', api_key=os.environ.get('ALGOLIA_API_KEY'), ...)&#13;
result = avs.transcribe([&#13;
    "https://www.youtube.com/watch?v=qSBm7d3McRI"&#13;
])&#13;
&#13;
print(result)&#13;
# [&#13;
#    {&#13;
#      "objectID": "zOz-Sk4K-64-0",&#13;
#      "videoID": "zOz-Sk4K-64",&#13;
#      "videoTitle": "Welcome to Algolia DevCon! Keynote and product demos",&#13;
#      "videoDescription": "...",&#13;
#      "url": "https://youtu.be/zOz-Sk4K-64?t=0",&#13;
#      "thumbnail": "https://i.ytimg.com/...",&#13;
#      "text": "Hi everyone and welcome to DevCon 2022.",&#13;
#      "start": 0,&#13;
#      "end": 12,&#13;
#      "categories": [],&#13;
#      "context": {&#13;
#        "before": {&#13;
#          "start": 0,&#13;
#          "text": ""&#13;
#        },&#13;
#        "after": {&#13;
#          "start": 12,&#13;
#          "text": "I'm thrilled to be here with you today at Algolia's first ever developer conference"&#13;
#        }&#13;
#      }&#13;
#    },&#13;
#    ...&#13;
# ]&#13;
</code></pre>
<h2 class="translated"><a id="configuration" class="anchor" href="#configuration" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a>配置</h2>
<p class="translated">一旦索引中有了一些数据，就应该调整一些设置来提供最佳的搜索体验。我们可以通过Algolia仪表盘或我个人最喜欢的Algolia CLI来实现这一点！我们准备了一个配置文件，您可以直接上传到您新创建的索引中，以获得开箱即用的最佳设置:</p>
<pre><code class="lang:sh decode:true"># Download the settings file from the repository or fetch it manually&#13;
wget https://github.com/algolia-samples/avsearch/blob/main/examples/settings.json.example&#13;
&#13;
# Transcription index name&#13;
export MY_INDEX_NAME=''&#13;
&#13;
# Overwrite index settings&#13;
algolia settings settings set $MY_INDEX_NAME -F settings.json.example&#13;
</code></pre>
<p class="translated">如果您不熟悉我们的CLI，您可以在这里找到更多相关信息<a href="https://www.algolia.com/developers/algolia-cli/">。如果仪表板更适合您，您还可以通过导航到您的索引，单击“管理索引”，然后选择“导入配置”来上传</a><a href="https://github.com/algolia-samples/avsearch/blob/main/examples/settings.json.example">配置</a>。</p>
<h2 class="translated"><a id="building-a-frontend" class="anchor" href="#building-a-frontend" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a>建筑前端</h2>
<p class="translated">我构建了一个自动完成搜索体验(包括cmd-K绑定)来简化与现有的<a href="https://algolia.com/devcon"> Algolia开发者大会主页</a>的整合。让搜索界面成为模态界面让我可以提供一个丰富的带有预览和缩略图空间的UX，而不需要重新设计整个主页。Algolia的AutcompleteJS库非常适合构建这种类型的自动完成体验。我使用我们自己的<a href="https://www.algolia.com/blog/ux/replicating-the-algolia-documentation-search-with-autocomplete/">文档搜索</a>作为灵感的模型。大预览窗格为用户提供了视频脚本的更多背景信息，帮助他们找到合适的剪辑。</p>
<p class="translated"><img loading="lazy" class="size-large wp-image-17647 aligncenter" src="../Images/fb1caa88cb2f75f3548949f5a1622670.png" alt="A/VSearch Example Frontend" srcset="https://blog-api.algolia.com/wp-content/uploads/2022/12/avsearch-frontend-476x400.png 476w, https://blog-api.algolia.com/wp-content/uploads/2022/12/avsearch-frontend-212x178.png 212w, https://blog-api.algolia.com/wp-content/uploads/2022/12/avsearch-frontend.png 725w" sizes="(max-width: 476px) 100vw, 476px" data-original-src="https://blog-api.algolia.com/wp-content/uploads/2022/12/avsearch-frontend-476x400.png"/></p>
<p class="translated">我研究了AutocompleteJS的插件架构，包括用于查询建议和点击事件的官方插件。我还创建了一个自定义插件，将选定的视频加载到同一网页上的嵌入式iFrame中(<code>createLoadVideoPlugin</code>)。</p>
<p class="translated">你可以在代码回购的<code>examples</code>目录中看到这个例子前端或者尝试一下<a href="https://avsearch.vercel.app">现场演示</a>。</p>
<h2 class="translated"><a id="wrap-up" class="anchor" href="#wrap-up" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a>总结起来</h2>
<p class="translated">如果您对A/VSearch有任何问题，如它如何工作、实施问题或功能要求，请随时在我们的<a href="https://discourse.algolia.com/">论坛</a>上留言！我们的团队很乐意听取您对/VSearch的意见，或者您可能有任何其他与Algolia相关的问题。</p>
<p class="translated">想开始抄写自己的内容吗？前往<a href="https://github.com/algolia-samples/avsearch"> GitHub库</a>获取最新版本！</p>
<p class="translated"><a class="aligncenter" title="Algolia Code Exchange" href="https://www.algolia.com/developers/code-exchange/showcase/generate-a-transcript-index-for-your-youtube-content-using-whisper/"> <img loading="lazy" class="wp-image-13777" src="../Images/7665551c18b687f25dcadc15cb213b7d.png" alt="Algolia Code Exchange" data-original-src="https://blog-api.algolia.com/wp-content/uploads/2022/01/CodeX@2x.png"/> </a></p>
<hr/>
<p class="translated"><em>我们希望您喜欢对A/VSearch的深入了解，以及我们如何使用它来增强DevCon会话搜索功能。如果你是Algolia的新手，你可以注册一个<a href="https://www.algolia.com/users/sign_up?utm_source=blog&amp;utm_medium=main-blog&amp;utm_campaign=devrel&amp;utm_id=blog-avsearch">免费等级账户</a>来试试我们。</em></p>
</div></div>    
</body>
</html>