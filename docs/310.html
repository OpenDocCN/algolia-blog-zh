<html>
<head>
<title>Integrate OCR into search in a package label-scanning app - Algolia Blog | Algolia Blog</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将OCR集成到搜索包标签扫描应用程序中- Algolia Blog | Algolia Blog</h1>
<blockquote>原文：<a href="https://www.algolia.com/blog/engineering/integrate-ocr-into-search-in-a-package-label-scanning-app/#0001-01-01">https://www.algolia.com/blog/engineering/integrate-ocr-into-search-in-a-package-label-scanning-app/#0001-01-01</a></blockquote><div><div class="css-t54cg4"><p class="translated">在没有T2的情况下，使用搜索栏来查找难以找到的信息听起来有些矛盾，但是以包装标签为例。快递公司以许多不同且不可预测的方式构建标签信息。通常，我们只是自己阅读标签并找到相关信息——在这种情况下，包裹是给谁的。但是我们更喜欢将OCR集成到搜索中。</p>
<p class="translated"><span>但是，如果有成千上万的标签，所有的结构都不一样——不同的内容，有时是手写的，几乎不可读的灰色阴影，奇怪的文本方向，随机的线条，图形，污迹和撕掉的角落，会怎么样？OCR有帮助吗？</span></p>
<p class="translated"><span>光学字符识别(OCR)尽最大努力从图像中提取文本，但产生的文本通常很大且无结构。此外，如果OCR软件不能破译一些字母，文本将有错别字。</span></p>
<p class="translated">这就是集成搜索技术的用武之地。<strong>具有健壮的、适应性强的相关性的搜索引擎可以将OCR的非结构化文本与结构化数据集进行匹配，并返回正确的结果。</strong>T11】</p>
<h2 class="translated"><a id="integrate-ocr-into-search" class="anchor" href="#integrate-ocr-into-search" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a> <span>将OCR集成到搜索中</span></h2>
<p class="translated"><span>我们将搜索引擎整合到两项技术中:</span></p>

<p class="translated"><span>本质上，我们扫描了一个标签，并使用谷歌云视觉API将标签转换为文本。然后，我们将不可预测的输出输入到搜索引擎中，搜索引擎将它与BambooHR的结构化数据进行匹配，找到并返回收件人的姓名。重要的是，我们不需要预处理或解析输入数据。这个工作流程也可以用于贴纸、邮票，甚至墙上的电影海报。</span></p>
<p class="translated">在线零售商和媒体公司正在利用这种OCR +搜索集成来查询他们的后端系统。</p>
<h2 class="translated"><a id="our-story-why-we-needed-to-integrate-ocr-into-search" class="anchor" href="#our-story-why-we-needed-to-integrate-ocr-into-search" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a> <span>我们的故事:为什么我们需要将OCR集成到搜索中</span></h2>
<p class="translated">每天，Algolia的员工都会在巴黎办公室收到大量包裹。我们办公室的协调员久美子一直在照顾他们。每当有新包裹到达，久美子就会搜索标签，找出是给谁的，然后找到Slack上的人，让他们知道他们的包裹正在前台等待。</p>
<p class="translated">但是阿尔戈利亚发展迅速。Kumiko开始花费越来越多的时间来手工处理包裹分发。在节日期间，它变得非常难以控制</p>
<p class="translated"><img loading="lazy" class="alignnone wp-image-8533" src="../Images/3c736de283b8c7517227187d557def63.png" alt="image of packages with different labels" srcset="https://blog-api.algolia.com/wp-content/uploads/2019/05/christmas-small-237x178.png 237w, https://blog-api.algolia.com/wp-content/uploads/2019/05/christmas-small-768x576.png 768w, https://blog-api.algolia.com/wp-content/uploads/2019/05/christmas-small-533x400.png 533w, https://blog-api.algolia.com/wp-content/uploads/2019/05/christmas-small.png 900w" sizes="(max-width: 524px) 100vw, 524px" data-original-src="https://blog-api.algolia.com/wp-content/uploads/2019/05/christmas-small-237x178.png"/></p>
<p class="translated"><span>显然，手动搬运不成规模。我认为应该有一种</span> <b>更快、更容易、可扩展的方式来帮助分派包裹。我决定为它建立一个web应用程序。我的目标是尽可能地自动化这个过程，从扫描标签到通知人们有空闲时间。</b></p>
<p class="translated">我最初想到使用条形码。不幸的是，我很快发现条形码不包含与二维码相同的数据。很多时候，它们只包含<a href="https://en.wikipedia.org/wiki/International_Article_Number"><span/></a><span>标识符。这些数字旨在查询私有运营商API以获取包裹的详细信息。</span></p>
<p class="translated"><span>所以我决定用光学字符识别引擎(</span><a href="https://en.wikipedia.org/wiki/Optical_character_recognition"><span>OCR</span></a><span>)读取包裹标签，并将OCR文本按原样发送给搜索引擎<em/>，将其与索引中的正确记录进行匹配。</span></p>
<h2 class="translated"><a id="how-to-integrate-ocr-into-search" class="anchor" href="#how-to-integrate-ocr-into-search" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a> <span>如何将OCR整合到搜索中</span></h2>
<h3 class="translated"><a id="step-1-finding-the-right-ocr-software" class="anchor" href="#step-1-finding-the-right-ocr-software" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a>第一步:寻找合适的OCR软件</h3>
<p class="translated"><span>有几个处理OCR部分的开源库。最受欢迎的是</span> <a href="https://github.com/tesseract-ocr/tesseract"> <span>宇宙魔方</span> </a> <span>。但是，您通常需要对图像</span>  <span>执行</span> <a href="https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality"> <span>一些预处理，然后再将其发送到Tesseract以识别字符(例如，去饱和、对比度、去倾斜)此外，我们收到的一些包裹标签是手写的！宇宙魔方不擅长读手写的字。</span></a></p>
<p class="translated"><span>谷歌的</span> <a href="https://cloud.google.com/vision/"> <span>视觉API </span> </a> <span>提供OCR功能，所以我决定试一试。除其他外，它规定:</span></p>
<ul>
<li aria-level="1" class="translated"><span>每月1，000次免费API调用(这足以启动)</span></li>
<li aria-level="1" class="translated"><span>手写字符检测</span></li>
</ul>
<p class="translated">我们将在第3步中看到它是如何工作的。首先，让我们看看将Algolia搜索与OCR集成的代码。</p>
<h3 class="translated"><a id="step-2-creating-the-react-app" class="anchor" href="#step-2-creating-the-react-app" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a> <b>第二步:创建React app </b></h3>
<p class="translated"><span>我创建了一个React app，安装了</span><a href="https://www.npmjs.com/package/react-webcam"><span>React web cam</span></a><span>组件来访问设备的摄像头。在内部，React组件利用了</span><a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia"><span>getuser media API</span></a><span>。</span></p>
<p class="translated"><span>一旦用户用手机捕捉到标签，应用程序会将其发送到快递后端。这负责将base64编码的图像代理到Google Vision API。然后，Vision返回一个JSON有效负载，其中包含文本形式的数据。</span></p>
<pre class="lang:javascript decode:true ">// Initialize the Google Cloud Vision client&#13;
visionClient = new vision.ImageAnnotatorClient();&#13;
&#13;
// Ask Vision API to return the text from the label&#13;
// https://cloud.google.com/vision/docs/ocr&#13;
const [result] = await visionClient.textDetection({&#13;
  image: {&#13;
    content: labelImage.data, // Uploaded image data&#13;
  },&#13;
});&#13;
&#13;
const detections = result.textAnnotations; // This contains all the text&#13;
const labelText = detections[0].description.replace(new RegExp("\n", "g"), " "); // Replace the line breaks by a space&#13;
</pre>
<h3 class="translated"><a id="step-3-reading-the-label-with-google-vision-api%c2%a0" class="anchor" href="#step-3-reading-the-label-with-google-vision-api%c2%a0" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a> <b>第三步:用谷歌视觉API读取标签</b></h3>
<p class="translated"><span>以下是谷歌视觉给我们的信息(以及我们最终将作为查询发送给搜索引擎的信息):</span></p>
<pre>ORY1\n0.7 KG\nDENOIX Clément\nALGOLIA\n55 rue d'Amsterdam\n75008 Paris, France\nC20199352333\nDIF4\nCYCLE\nlove of boo\nAnod&#13;
</pre>
<p class="translated">如你所见，l<span>Abel并不漂亮。它们包含许多噪音。相关信息就在那里的某个地方，被其他数据包围着。它们包含与递送人相关的字符，例如标签号、发件人地址等。此外，顺序并不一致，信息也不总是完整的，所以在发送给Algolia之前，我们不能依靠单词排序或元素位置来提取相关部分。我们将在步骤5中完成。首先，让我们看一下将要搜索的后端数据。</span></p>
<h3 class="translated"><a id="step-4-data-indexing-bamboohrs-back-end-data" class="anchor" href="#step-4-data-indexing-bamboohrs-back-end-data" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a> <b>第四步:数据索引BambooHR的后端数据</b></h3>
<p class="translated"><span>这部分不需要提供任何代码。索引来自其他系统的数据是所有搜索引擎的基础。其思想是从一个或多个系统中获取</span> <i> <span>相关的</span> </i> <span>数据，并将其全部推入一个称为索引的独立数据源。它在后端运行，运行频率与数据不断变化的性质相匹配。请注意，搜索引擎只需要一些与搜索目的相关的数据，用于查询、显示、排序和过滤。</span></p>
<p class="translated"><span> Algolia的API提供了<a href="https://www.algolia.com/doc/api-reference/api-methods/save-objects/">更新方法</a>来实现这一点。我们的文档提供了关于如何发送数据的教程。</span></p>
<h3 class="translated"><a id="step-5-searching-with-algolia" class="anchor" href="#step-5-searching-with-algolia" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a> <b>第五步:用Algolia搜索</b></h3>
<p class="translated">如你所见，谷歌的视觉应用编程接口给了我们大量的信息。但是搜索引擎怎么定位名字呢？</p>
<p class="translated"><span>幸运的是，</span><b>Algolia搜索API有一个有趣的参数</b><span>:</span><a href="https://www.algolia.com/doc/api-reference/api-parameters/removeWordsIfNoResults/"><code>removeWordsIfNoResults</code></a><span>。</span></p>
<p class="translated"><span>当您将此参数设置为</span> <code>allOptional</code> <span>并且引擎未能找到原始查询的任何结果时，</span> <i> <span>将进行第二次尝试，</span> </i> <span>将所有单词视为可选。这相当于将单词之间隐含的<code>AND</code>运算符转换为<code>OR</code>。</span></p>
<pre class="lang:javascript decode:true ">// Initialize the Algolia client and the Algolia employees index.&#13;
const algoliaClient = algoliaearch(process.env.ALGOLIA_APP_ID, process.env.ALGOLIA_API_KEY)&#13;
const index = algoliaClient.initIndex(process.env.ALGOLIA_INDEX_NAME);&#13;
&#13;
// Search our employees index for a match, using the `removeWordsIfNoResults=allOptional` option.&#13;
// https://www.algolia.com/doc/api-reference/api-parameters/removeWordsIfNoResults/&#13;
const algoliaResult = await index.search(labelText, {&#13;
    'removeWordsIfNoResults': 'allOptional'&#13;
})&#13;
</pre>
<p class="translated"><span>注意，<code>labelText</code>包含了Google Vision API返回的没有任何预处理的字符串(除了去掉<code>'\n’</code>)。我已经突出显示了搜索引擎从标签上的噪音中抽出的</span> <span>名称</span><span>(<code>DENOIX Clément</code>)——大海捞针:</span></p>
<pre>ORY1 0.7 KG <strong>DENOIX Clément</strong> ALGOLIA 55 rue d'Amsterdam 75008 Paris, France C20199352333 DIF4 CYCLE love of boo Anod&#13;
</pre>
<p class="translated"><span>通常，该参数有助于</span> <a href="https://www.algolia.com/doc/guides/managing-results/optimize-search-results/empty-or-insufficient-results/in-depth/why-use-remove-words-if-no-results/"> <span>在查询过于严格</span> </a> <span>时改善结果。在我的情况下，它允许我发送未经处理的提取数据。我能够信任Algolia引擎“忽略”查询中无关的单词，只考虑重要的单词。</span></p>
<pre class="lang:json decode:true ">{&#13;
  "displayName": "Clement Denoix",&#13;
  "firstName": "Clement",&#13;
  "lastName": "Denoix",&#13;
  "location": "Paris",&#13;
  "slack": {&#13;
    "id": "U0000000",&#13;
    "handle": "clement.denoix",&#13;
    "image": "https://avatars.slack-edge.com/2018-04-03/340713326613_2890719b5a8d4506f30c_512.jpg"&#13;
  },&#13;
}&#13;
</pre>
<p class="translated">只剩下几个步骤:从Algolia搜索结果列表中提取第一个匹配项并显示出来。从那里，我们的办公室经理可以确认结果，并自动向正确的员工发送Slack消息。</p>
<p class="translated"><span>这是该应用的完整流程图:</span></p>
<p class="translated"><img loading="lazy" class="alignnone wp-image-12313" src="../Images/49fab84910bd130d42e54bd54d013001.png" alt="Image of oct label reading process" srcset="https://blog-api.algolia.com/wp-content/uploads/2021/07/ocr-label-reading-process-320x101.jpeg 320w, https://blog-api.algolia.com/wp-content/uploads/2021/07/ocr-label-reading-process-720x228.jpeg 720w, https://blog-api.algolia.com/wp-content/uploads/2021/07/ocr-label-reading-process-768x243.jpeg 768w, https://blog-api.algolia.com/wp-content/uploads/2021/07/ocr-label-reading-process-1536x486.jpeg 1536w, https://blog-api.algolia.com/wp-content/uploads/2021/07/ocr-label-reading-process.jpeg 1920w" sizes="(max-width: 554px) 100vw, 554px" data-original-src="https://blog-api.algolia.com/wp-content/uploads/2021/07/ocr-label-reading-process-320x101.jpeg"/></p>
<p class="translated"><span>如此处所示:我们拍下包装标签的照片。该应用程序通过Express后端将其发送到Google Vision API。Google Vision返回一个包含已识别文本的JSON有效负载，后端将其作为搜索查询发送给Algolia。搜索引擎使用</span> <code>removeWordsIfNoResults</code> <span>选项来确保匹配成功。Algolia然后返回一个匹配记录的列表，后端从中提取第一个命中的记录，并将其返回给React应用程序。</span></p>
<h2 class="translated"><a id="conclusion-next-steps" class="anchor" href="#conclusion-next-steps" aria-hidden="true"> <svg aria-hidden="true" class="octicon octicon-link" version="1.1" viewbox="0 0 16 16"> <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"/> </svg> </a> <span>结论&amp;下一步</span></h2>
<p class="translated">Algolia强大的搜索引擎不仅限于搜索框。凭借想象力，您可以将Algolia的使用远远超出盒子的范围，并解决各种问题。</p>
<p class="translated"><span>标签读取只是OCR集成的一种。有<em>图像识别，</em>在线零售商可以从图像中识别服装的类型、风格、颜色和尺寸。还有<em>语音识别，</em>网站可以与人们说话的非结构化方式互动。</span></p>
<p class="translated">有很多方法可以做到这一点。在这种情况下，我们使用搜索引擎的内置功能来实现这一点，这些功能使它能够根据非结构化查询数据的多样性和不可预测性来调整其相关性算法。下一步是将人工智能和机器学习结合起来，使搜索引擎的适应性和用例范围更大。</p>
</div></div>    
</body>
</html>